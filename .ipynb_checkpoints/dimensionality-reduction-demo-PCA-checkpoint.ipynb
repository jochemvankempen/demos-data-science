{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "administrative-disorder",
   "metadata": {},
   "source": [
    "# Dimensionality-reduction-demo-PCA\n",
    "\n",
    "In this notebook, I will discuss how to perform principal component analysis (PCA). I will use [data](https://doi.gin.g-node.org/10.12751/g-node.b0mnn2/) from a [recently published paper in Neuron](https://www.cell.com/neuron/fulltext/S0896-6273(20)30995-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627320309958%3Fshowall%3Dtrue). It is data simultaneously recorded from V1 and V4 using 16-contact laminar electrodes during an attention-demanding task. For specifics about the task and recordings I'll refer you to the paper, but the important things to know to follow the analysis below are:\n",
    "- Three stimuli were presented\n",
    "    - the stimuli were exactly the same on each trial\n",
    "    - one of the stimuli was presented inside the RF of the recorded neurons\n",
    "- The cue, indicating which of the 3 stimuli to attend to, was presented after the stimuli\n",
    "\n",
    "See [figure 1](https://www.cell.com/neuron/fulltext/S0896-6273(20)30995-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627320309958%3Fshowall%3Dtrue#fig1) for more details on the paradigm.\n",
    "\n",
    "Below, I'll load the packages and the data, give a brief description of the data, and then go over the PCA procedure step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom packages to sys.path\n",
    "# import sys\n",
    "# sys.path.insert(0, '/Users/jochemvankempen/repositories')\n",
    "# sys.path.insert(0, '/Users/jochemvankempen/repositories/Thiele-lab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams \n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "# plt.rcParams['animation.ffmpeg_path'] = '/usr/local/bin/ffmpeg'\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "# import pandas as pd \n",
    "import os\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# custom packages/modules\n",
    "from pyplotj import animj\n",
    "from neuroimport import matlabimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default plot params\n",
    "rcParams['font.size'] =15\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-deficit",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path and URL\n",
    "data_path = '/Users/jochemvankempen/NCL/gratc/data/processed/Wyman/2016-01-22'\n",
    "# data_url = 'https://gin.g-node.org/jochemvankempen/Thiele-attention-gratc-V1-V4-laminar/src/master/data/processed/W/2016-01-22/'\n",
    "\n",
    "# load data\n",
    "loadfilename = os.path.join(data_path, 'MUAe.mat')\n",
    "data = matlabimport.load_data(loadfilename,'StimAlign','CueAlign','area','unitList')\n",
    "loadfilename = os.path.join(data_path, 'trialdata.mat')\n",
    "trialdata = matlabimport.load_trialdata(loadfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-september",
   "metadata": {},
   "source": [
    "Now lets see what the files contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'data is a {type(data)}')\n",
    "print('It contains the keys :', *data.keys(), sep='\\n', end='\\n', file=sys.stdout, flush=True)    \n",
    "    \n",
    "print('\\nIn data, the element StimAlign contains: ', *data['StimAlign'].keys(), sep='\\n')\n",
    "    \n",
    "print('\\nTimeStamps is a', np.shape(data['StimAlign']['TimeStamps']), 'vector')\n",
    "print('Samples is a', np.shape(data['StimAlign']['Samples']), 'matrix with ', \n",
    "      np.shape(data['StimAlign']['Samples'])[0], ' channels,', \n",
    "      np.shape(data['StimAlign']['Samples'])[1], ' trials and', \n",
    "      np.shape(data['StimAlign']['Samples'])[2], ' time points \\n')\n",
    "\n",
    "\n",
    "print(f'trialdata is a {type(trialdata)} , containing the keys :', *trialdata.keys(), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-stupid",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some parameters\n",
    "\n",
    "# define areas\n",
    "areas = np.unique(data['area'])\n",
    "num_areas = np.size(areas)\n",
    "\n",
    "# define conditions\n",
    "conditions = ['Attend RF', 'Attend away1', 'Attend away2']\n",
    "num_cond = np.size(np.unique(trialdata['attend']))\n",
    "\n",
    "# define time windows\n",
    "time_window = {\n",
    "    'Baseline': [-0.25, 0], \n",
    "    'Stimulus': [0.03, 0.2],\n",
    "    'Sustained':[0.2, 1],\n",
    "    'Attend': [0.6, 1],\n",
    "    'Cue': [-0.2, 1]\n",
    "    }\n",
    "\n",
    "print(f'Brain areas recorded from:{areas}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-magnet",
   "metadata": {},
   "source": [
    "# Data inspection\n",
    "## Stimulus-aligned activity\n",
    "Next we have a look at the data, starting with the trial-averaged activity aligned to stimulus onset. \n",
    "\n",
    "As you can see, there is a reliably stimulus-induced response on most of the channels. \n",
    "\n",
    "Note: we subtract baseline activity to get a good idea of any changes to the activity induced by stimulus presentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average stim-aligned activity\n",
    "# ----------------------------------\n",
    "\n",
    "event = 'StimAlign'\n",
    "\n",
    "# extract the indices for the baseline time window\n",
    "cond1 = data[event]['TimeStamps'][0] > time_window['Baseline'][0] # time points larger than time_window['Baseline'][0]\n",
    "cond2 = data[event]['TimeStamps'][0] <= time_window['Baseline'][1] # time points smaller than time_window['Baseline'][1]\n",
    "idx_time = np.where(cond1 & cond2)[0]\n",
    "\n",
    "# compute trial-averaged baseline activity for each channel\n",
    "baseline_activity = data[event]['Samples'][:,:,idx_time].mean(axis=(1,2))\n",
    "\n",
    "# loop over areas to plot baseline-subtracted activity\n",
    "plt.figure(figsize=(13,6)) \n",
    "for iarea, area in enumerate(areas):\n",
    "    \n",
    "    idx_unit = np.where(data['area']==area)[0]# select units to plot per area\n",
    "  \n",
    "    ax = plt.subplot(1,num_areas,iarea+1)\n",
    "    \n",
    "    for iunit in idx_unit:\n",
    "                          \n",
    "        ax.plot( data[event]['TimeStamps'][0], (data[event]['Samples'][iunit,:,:].mean(axis=0) - baseline_activity[iunit]) )\n",
    "\n",
    "    ax.set(xlabel='time from stimulus onset [s]', ylabel='Activity')\n",
    "    ax.set_xlim(left=-0.2, right=1.0)\n",
    "    ax.set(title=area)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-carter",
   "metadata": {},
   "source": [
    "## Cue-aligned activity\n",
    "\n",
    "The information which of the three stimuli attention should be directed towards is provided by the presentation of a central cue that matches the colour of one of the three stimuli. The dictionary element `data['CueAlign']` contains the data aligned to the onset of the cue.\n",
    "\n",
    "This plot shows the trial and channel averaged activity for each of the three attention conditions. When attention is directed towards the RF, activity increases after onset of the cue relative to the other two conditions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over areas to plot baseline-subtracted activity aligned to cue\n",
    "plt.figure(figsize=(13,6)) \n",
    "for iarea, area in enumerate(areas):\n",
    "    \n",
    "    idx_unit = np.where(data['area']==area)[0]# select units to plot per area\n",
    "  \n",
    "    ax = plt.subplot(1,num_areas,iarea+1)\n",
    "    \n",
    "    for icond, cond in enumerate(conditions):\n",
    "\n",
    "        # find trials for attention condition\n",
    "        idx_trial = trialdata['attend']==(icond+1)\n",
    "        \n",
    "        # extract data for this area/condition, subtract baseline activity\n",
    "        plotdata = data['CueAlign']['Samples'][idx_unit,:,:] # select units\n",
    "        plotdata = plotdata[:,idx_trial,:].mean(axis=1) # select and average over trials\n",
    "        plotdata = plotdata - np.matlib.repmat(baseline_activity[idx_unit, np.newaxis], 1, np.shape(plotdata)[1]) # subtract baseline activity\n",
    "           \n",
    "        # get y, y_err    \n",
    "        y = plotdata.mean(axis=0)\n",
    "        y_err = plotdata.std(axis=0)/np.sqrt(np.size(idx_unit)) # SE\n",
    "\n",
    "        # plot                      \n",
    "        p = ax.plot( data['CueAlign']['TimeStamps'][0],  y)\n",
    "        ax.fill_between(data['CueAlign']['TimeStamps'][0], y-y_err, y+y_err, color=p[0].get_color(), alpha=0.1)\n",
    "        \n",
    "    ax.set(xlabel='time from cue onset [s]', ylabel='Activity')\n",
    "    ax.set_xlim(left=-0.2, right=1.0)\n",
    "    ax.set_ylim(bottom=0, top=0.0015)\n",
    "    ax.set(title=area)\n",
    "    if iarea==(num_areas-1):\n",
    "        ax.legend(conditions)\n",
    "        \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-finding",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "Now that we have a basic understanding of the activity present in this data, we will cover eigendecomposition and principal component analysis (PCA).\n",
    "\n",
    "The goal is to find a low-dimensional representation that captures much of the variance (information) of the original high-dimensional data. In this case, we have a recording of 16 channels per area, so our data is 16-dimensional. \n",
    "\n",
    "To some degree, neural activity covaries between the channels within one area (and possibly between areas), i.e. the trial-to-trial variability in neural responses is shared across channels. This covariance reveals structure in the data; we assume that:\n",
    "- directions of large variation represent signal (interesting features in the data)\n",
    "- directions of small variation represent noise \n",
    "\n",
    "The goal of PCA is to find these directions of maximal variance. Once identified, we can project the data onto these directions and represent the data in a lower dimensional space. The directions of maximal variance in the data are the directions indicated by [the eigenvectors](https://www.youtube.com/watch?v=PFDu9oVAE-g) of the covariance matrix.\n",
    "\n",
    "How do we perform PCA?\n",
    "1. Subtract the mean\n",
    "2. Calculate the eigenvectors of the covariance matrix, sorted by the corresponding eigenvalue\n",
    "3. Project the data onto the new basis\n",
    "\n",
    "\n",
    "## Covariance matrix\n",
    "Lets first have a look at the covariance and correlation coefficients for each area. We'll start by doing this for the average activity during a specified timewindow (`time_window['Cue']`). \n",
    "\n",
    "Having averaged over time, our data are matrices of size (16 channels [per area] $\\times$ 746 trials). We will need to transpose this matrix to follow convention and allow the necessary matrix multiplication. Thus, we will then have matrix $X$ of size 746 $\\times$ 16.\n",
    "\n",
    "The covariance matrix is obtained by $X^{T}X$ (`np.cov` also normalises) and results in a matrix of size 16 $\\times$ 16, with an entry on both axes for each channel. Values in this matrix indicate whether activity between channel pairs co-varies across trials (with unit: activity$^{2}$). The covariance matrix $X^{T}X$ encodes all the linear interactions among the variables/columns of X.\n",
    "\n",
    "I also plotted the correlation coefficients, which is the normalised version of the covariance matrix (normalised by $\\sqrt{var(x_{1})var(x_{2})}$ ), scaling the covariance values between -1 and 1. This sometimes gives a little more insight into which channels/features covary. For instance in V4, the activity in one of the channels is much larger than the others, which makes it difficult to see which other channels covary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'CueAlign'\n",
    "\n",
    "# get activity per channel and trial\n",
    "cond1 = data[event]['TimeStamps'][0] > time_window['Attend'][0]\n",
    "cond2 = data[event]['TimeStamps'][0] <= time_window['Attend'][1]\n",
    "idx_time = cond1 & cond2\n",
    "attention_activity = data[event]['Samples'][:,:,idx_time].mean(axis=2) #\n",
    "\n",
    "# get corresponding baseline activity\n",
    "cond1 = data['StimAlign']['TimeStamps'][0] > time_window['Baseline'][0]\n",
    "cond2 = data['StimAlign']['TimeStamps'][0] <= time_window['Baseline'][1]\n",
    "idx_time = cond1 & cond2\n",
    "baseline_activity = data['StimAlign']['Samples'][:,:,idx_time].mean(axis=(2))\n",
    "\n",
    "attention_activity = attention_activity - baseline_activity\n",
    "\n",
    "# mean centre\n",
    "attention_activity = attention_activity - np.mean(attention_activity, axis=1)[:,np.newaxis]\n",
    "\n",
    "plotdata = {}\n",
    "plt.figure(figsize=(8,6)) \n",
    "for iarea, area in enumerate(areas):\n",
    "    \n",
    "    idx_unit = data['area']==area # select units to plot per area\n",
    "\n",
    "    plotdata[area] = attention_activity[idx_unit,:].T # transpose to (trials x channels) \n",
    "    \n",
    "    # calculate covariance and correlation coefficient matrix\n",
    "    #     cov_matrix = plotdata[area].T @ plotdata[area]\n",
    "    cov_matrix = np.cov(plotdata[area], bias=True, rowvar=False)\n",
    "    corr_matrix = np.corrcoef(plotdata[area], rowvar=False)\n",
    "    \n",
    "    # plot covariance\n",
    "    ax = plt.subplot(num_areas, 2, 1+(num_areas*iarea))\n",
    "    ax.imshow(cov_matrix) \n",
    "    ax.set_xlabel('Channel')\n",
    "    ax.set_ylabel('Channel')\n",
    "    ax.set_title(area + ' - covariance matrix')\n",
    "\n",
    "    # plot correlations\n",
    "    ax = plt.subplot(num_areas, 2, 2+(num_areas*iarea))\n",
    "    ax.imshow(corr_matrix) \n",
    "    ax.set_xlabel('Channel')\n",
    "    ax.set_ylabel('Channel')\n",
    "    ax.set_title(area + ' - correlation coefficients')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-ecuador",
   "metadata": {},
   "source": [
    "## Eigendecomposition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def linalg_change_basis(X, evecs):\n",
    "    \"\"\"\n",
    "    Projects data onto a new basis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array of floats\n",
    "        Data matrix each column corresponding to a different variable\n",
    "    evecs : numpy array of floats\n",
    "        new orthonormal basis; columns correspond to basis vectors\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Y : numpy array of floats \n",
    "        Data matrix expressed in new basis\n",
    "    \"\"\"        \n",
    "    \n",
    "    # check the dimensions match\n",
    "    assert np.shape(X)[1]==np.shape(evecs)[0], 'Inner dimensions X and evecs do not match'\n",
    "    \n",
    "    Y = X@evecs\n",
    "    return Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-peeing",
   "metadata": {},
   "source": [
    "### An example using two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param\n",
    "idx_unit = [6,7] # select units to plot \n",
    "\n",
    "# extract data\n",
    "data_mat = plotdata['V1'][:,idx_unit]\n",
    "data_mat = data_mat*1e3 # change unit for plotting ease\n",
    "\n",
    "# compute covariance matrix\n",
    "cov_matrix = np.cov(data_mat, bias=True, rowvar=False)\n",
    "\n",
    "# eigendecomposition\n",
    "evals, evectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "# sort eigenvalues/vectors by eigenvalue\n",
    "index = np.flip(np.argsort(evals))\n",
    "evals = evals[index]\n",
    "evectors = evectors[:, index]\n",
    "\n",
    "# project data onto orthonormal basis\n",
    "data_proj = linalg_change_basis(data_mat, evectors)\n",
    "\n",
    "\n",
    "# Note that the same can be achieved using singular value decomposition (svd)\n",
    "# U,S,V = np.linalg.svd(cov_matrix)\n",
    "# data_proj = linalg_change_basis(data_mat, U)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-characteristic",
   "metadata": {},
   "source": [
    "#### Inspect matrix sizes and orthonormal basis\n",
    "We can inspect the matrix sizes and some key properties of the eigendecomposition/data in order to get a better understanding of what is happening here. \n",
    "\n",
    "Some key properties of PCA:\n",
    "1. Eigenvectors are orthogonal\n",
    "2. As a result, the components (columns) of the projected data are uncorrelated\n",
    "3. The variance of each component of the projected data is equal to its corresponding eigenvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix sizes\n",
    "print(f'data_mat shape is {np.shape(data_mat)}')\n",
    "print(f'cov_matrix shape, obtained by (data_mat.T @ data_mat), is {np.shape(cov_matrix)}')\n",
    "print(f'eigenvector matrix shape is {np.shape(evectors)}')\n",
    "print(f'data_proj shape, obtained by (data_mat @ evectors), is {np.shape(data_proj)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key property 1.\n",
    "# Verify the eigenvectors are orthogonal.\n",
    "\n",
    "# if eigenvectors are orthogonal, the dot product between eigenvectors is zero, but the dot product with itself is 1. \n",
    "# The matrix multiplication between eigenvectors should thus result in the identity matrix.\n",
    "print(np.round(evectors.T@evectors))\n",
    "\n",
    "# Note that the eigendecomposition of a symmetric matrix always has orthogonal eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key property 2.\n",
    "# Verify the components of the projected data are uncorrelated (within numerical precision)\n",
    "\n",
    "corr_matrix = np.corrcoef(data_proj, rowvar=False)\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key property 3.\n",
    "# Verify that the variance of the components is equal to their corresponding eigenvalue\n",
    "\n",
    "print(np.var(data_proj, axis=0))\n",
    "print(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "# --------\n",
    "num_plots = 4\n",
    "\n",
    "plt.figure(figsize=(13,6)) \n",
    "\n",
    "# plot covariance matrix\n",
    "ax = plt.subplot(1, num_plots, 1)\n",
    "ax.imshow(cov_matrix) \n",
    "ax.set_xlabel('Channel')\n",
    "ax.set_ylabel('Channel')\n",
    "ax.set_title('Covariance matrix')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_xticklabels(idx_unit)\n",
    "ax.set_yticklabels(idx_unit)\n",
    "\n",
    "# plot data covariance with eigenvectors\n",
    "ax = plt.subplot(1, num_plots, 2)\n",
    "ax.scatter(data_mat[:,0], data_mat[:,1], alpha=0.2)\n",
    "ax.plot([0, evectors[0, 0]], [0, evectors[1, 0]], color='r', linewidth=3, label='Basis vector 1')\n",
    "ax.plot([0, evectors[0, 1]], [0, evectors[1, 1]], color='b', linewidth=3, label='Basis vector 2')\n",
    "ax.set_xlabel('Activity channel ' + str(idx_unit[0]))\n",
    "ax.set_ylabel('Activity channel ' + str(idx_unit[1]))\n",
    "ax.set_title('Data & eigenvectors')\n",
    "ax.axis('square')\n",
    "# ax.legend()\n",
    "\n",
    "# plot eigenvalues\n",
    "ax = plt.subplot(1, num_plots, 3)\n",
    "ax.plot(np.arange(1, len(evals) + 1), evals, 'o-k')\n",
    "ax.set_xlabel('Component')\n",
    "ax.set_ylabel('Eigenvalue')\n",
    "ax.set_title('Scree plot')\n",
    "ax.set_xticks(np.arange(1, len(evals) + 1))\n",
    "ax.axis('square')\n",
    "ax.set_xticklabels(np.arange(0, len(evals)))\n",
    "\n",
    "# plot data projected onto orthonormal basis\n",
    "ax = plt.subplot(1, num_plots, 4)\n",
    "ax.scatter(data_proj[:,0], data_proj[:,1], alpha=0.2)\n",
    "ax.set_xlabel('Component 0')\n",
    "ax.set_ylabel('Component 1')\n",
    "ax.set_title('Data projection')\n",
    "ax.axis('square')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-apartment",
   "metadata": {},
   "source": [
    "# Achieve the same result using PCA\n",
    "We can replicate this analysis by using the implemented principal component analysis (PCA) function of the `sklearn.decomposition` package in only a few lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(data_mat)\n",
    "evectors = pca.components_.T # transpose evectors\n",
    "evals = pca.explained_variance_\n",
    "\n",
    "cov_matrix = pca.get_covariance()\n",
    "\n",
    "data_proj = linalg_change_basis(data_mat, evectors)\n",
    "\n",
    "\n",
    "# plotting, repeat of code in previous cell\n",
    "# -----------------------------------------\n",
    "plt.figure(figsize=(13,6)) \n",
    "\n",
    "# plot covariance matrix\n",
    "ax = plt.subplot(1, num_plots, 1)\n",
    "plt.imshow(cov_matrix) \n",
    "ax.set_xlabel('Channel')\n",
    "ax.set_ylabel('Channel')\n",
    "ax.set_title('Covariance matrix')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_xticklabels(idx_unit)\n",
    "ax.set_yticklabels(idx_unit)\n",
    "\n",
    "# plot data covariance with eigenvectors\n",
    "ax = plt.subplot(1, num_plots, 2)\n",
    "ax.scatter(data_mat[:,0], data_mat[:,1], alpha=0.2)\n",
    "ax.plot([0, evectors[0, 0]], [0, evectors[1, 0]], color='r', linewidth=3, label='Basis vector 1')\n",
    "ax.plot([0, evectors[0, 1]], [0, evectors[1, 1]], color='b', linewidth=3, label='Basis vector 2')\n",
    "ax.set_xlabel('Activity channel ' + str(idx_unit[0]))\n",
    "ax.set_ylabel('Activity channel ' + str(idx_unit[1]))\n",
    "ax.set_title('Data & eigenvectors')\n",
    "ax.axis('square')\n",
    "# plt.legend()\n",
    "\n",
    "# plot eigenvalues\n",
    "ax = plt.subplot(1, num_plots, 3)\n",
    "ax.plot(np.arange(1, len(evals) + 1), evals, 'o-k')\n",
    "ax.set_xlabel('Component')\n",
    "ax.set_ylabel('Eigenvalue')\n",
    "ax.set_title('Scree plot')\n",
    "ax.set_xticks(np.arange(1, len(evals) + 1))\n",
    "ax.axis('square')\n",
    "ax.set_xticklabels(np.arange(0, len(evals)))\n",
    "\n",
    "# plot data projected onto orthonormal basis\n",
    "ax = plt.subplot(1, num_plots, 4)\n",
    "ax.scatter(data_proj[:,0], data_proj[:,1], alpha=0.2)\n",
    "ax.set_xlabel('Component 0')\n",
    "ax.set_ylabel('Component 1')\n",
    "ax.set_title('Data projection')\n",
    "ax.axis('square')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-project",
   "metadata": {},
   "source": [
    "# Expand to higher dimensions\n",
    "Now we use all available channels for one single area. In this case we have 16 channels, so we have a 16-dimensional space that we project to a few principal components that capture most of the variance in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "data_mat = plotdata['V1']\n",
    "data_mat = data_mat*1e3 # change unit for plotting ease\n",
    "\n",
    "# apply PCA\n",
    "pca = PCA(n_components=3).fit(data_mat)\n",
    "\n",
    "# get components/eigenvectors and eigenvalues\n",
    "evectors = pca.components_.T # transpose evectors\n",
    "evals = pca.explained_variance_\n",
    "\n",
    "cov_matrix = pca.get_covariance()\n",
    "\n",
    "data_proj = linalg_change_basis(data_mat, evectors)\n",
    "\n",
    "# data_proj = evectors@data_mat.T\n",
    "# data_proj = data_proj.T\n",
    "\n",
    "# plotting\n",
    "# --------\n",
    "plt.figure(figsize=(13,4)) \n",
    "\n",
    "# plot covariance matrix\n",
    "ax = plt.subplot(1, num_plots, 1)\n",
    "ax.imshow(cov_matrix) \n",
    "ax.set_xlabel('Channel')\n",
    "ax.set_ylabel('Channel')\n",
    "ax.set_title('Covariance matrix')\n",
    "\n",
    "\n",
    "# plot eigenvectors\n",
    "ax = plt.subplot(1, num_plots, 2, projection='3d')\n",
    "ax.view_init(elev=10., azim=260)\n",
    "ax.plot([0, evectors[0,0]], [0, evectors[1,0]], [0,evectors[2,0]], color='r', linewidth=3, label='Basis vector 1')\n",
    "ax.plot([0, evectors[0,1]], [0, evectors[1,1]], [0,evectors[2,1]], color='b', linewidth=3, label='Basis vector 2')\n",
    "ax.plot([0, evectors[0,2]], [0, evectors[1,2]], [0,evectors[2,2]], color='k', linewidth=3, label='Basis vector 3')\n",
    "# ax.set_xlabel('Component 0')\n",
    "# ax.set_ylabel('Component 1')\n",
    "# ax.set_zlabel('Component 2')\n",
    "\n",
    "# plot eigenvalues\n",
    "ax = plt.subplot(1, num_plots, 3)\n",
    "ax.plot(np.arange(1, len(evals) + 1), evals, 'o-k')\n",
    "ax.set_xlabel('Component')\n",
    "ax.set_ylabel('Eigenvalue')\n",
    "ax.set_title('Scree plot')\n",
    "ax.set_xticks(np.arange(5, len(evals)+1, 5))\n",
    "ax.set_xticklabels(np.arange(4, len(evals), 5))\n",
    "# ax.axis('square')\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, num_plots, 4, projection='3d')\n",
    "ax.view_init(elev=10., azim=260)\n",
    "    \n",
    "for icond, cond in enumerate(conditions):\n",
    "\n",
    "    # find trials for attention condition\n",
    "    idx_trial = trialdata['attend']==(icond+1)\n",
    "\n",
    "    # extract data for this condition\n",
    "    x = data_proj[idx_trial,0] # select trials, first component\n",
    "    y = data_proj[idx_trial,1] # select trials, second component\n",
    "    z = data_proj[idx_trial,2] # select trials, third component\n",
    "\n",
    "    # plot                      \n",
    "    p = ax.scatter(x,y,z)\n",
    "#     ax.plot(x,y,z, '')\n",
    "#     ax.fill_between(data['CueAlign']['TimeStamps'][0], y-y_err, y+y_err, color=p[0].get_color(), alpha=0.1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-kennedy",
   "metadata": {},
   "source": [
    "# PCA over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply PCA over time\n",
    "# -----------------------\n",
    "\n",
    "# extract data over time\n",
    "event = 'CueAlign'\n",
    "idx_unit = np.where(data['area']=='V1')[0]# select units to plot per area\n",
    "\n",
    "# get activity per channel and trial\n",
    "cond1 = data[event]['TimeStamps'][0] > time_window['Cue'][0]\n",
    "cond2 = data[event]['TimeStamps'][0] <= time_window['Cue'][1]\n",
    "idx_time = cond1 & cond2\n",
    "\n",
    "attention_activity = data[event]['Samples'][:,:,idx_time] #\n",
    "attention_timeStamps = data[event]['TimeStamps'][0][idx_time]\n",
    "\n",
    "# repmat baseline_activity\n",
    "baseline_activity = np.repeat(baseline_activity[:, :, np.newaxis], np.shape(attention_activity)[2], axis=2) # indexing with np.newaxis inserts a new 3rd dimension, which we then repeat the array along\n",
    "\n",
    "# subtract baseline\n",
    "attention_activity = attention_activity - baseline_activity\n",
    "\n",
    "# unit sub-selection\n",
    "attention_activity = attention_activity[idx_unit,:,:]\n",
    "attention_activity = attention_activity*1e3 # change unit for plotting ease\n",
    "\n",
    "# reshape: concatenate across trials\n",
    "pca_activity = np.reshape(attention_activity, (np.shape(idx_unit)[0],-1))\n",
    "\n",
    "# mean center\n",
    "pca_activity = pca_activity - np.mean(pca_activity, axis=1)[:,np.newaxis]\n",
    "pca_activity = pca_activity.T\n",
    "\n",
    "# apply PCA\n",
    "pca = PCA(n_components=3).fit(pca_activity)\n",
    "evectors = pca.components_.T\n",
    "evals = pca.explained_variance_\n",
    "\n",
    "# project onto eigenvectors\n",
    "data_proj = linalg_change_basis(pca_activity, evectors)\n",
    "\n",
    "\n",
    "# reshape (back) to (component x trial x time)\n",
    "data_proj = np.reshape(data_proj.T, (3, -1, np.shape(attention_activity)[2]))\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(13,4)) \n",
    "\n",
    "for ipc in range(pca.n_components):\n",
    "    ax = plt.subplot(1, pca.n_components+1, ipc+1)\n",
    "\n",
    "    ax.plot(attention_timeStamps, data_proj[ipc, trialdata['attend']==1, :].mean(axis=0))\n",
    "    ax.plot(attention_timeStamps, data_proj[ipc, trialdata['attend']==2, :].mean(axis=0))\n",
    "    ax.plot(attention_timeStamps, data_proj[ipc, trialdata['attend']==3, :].mean(axis=0))\n",
    "    ax.set_title('Component ' + str(ipc))\n",
    "\n",
    "    \n",
    "# get explained variance\n",
    "evals_percentage = pca.explained_variance_\n",
    "ax = plt.subplot(1, pca.n_components+1, pca.n_components+1)\n",
    "ax.plot(np.arange(1, len(evals_percentage) + 1), evals_percentage, 'o-k')\n",
    "ax.set_xlabel('Component')\n",
    "ax.set_ylabel('Variance explained [%]')\n",
    "ax.set_title('Scree plot')\n",
    "ax.set_xticks(np.arange(5, len(evals)+1, 5))\n",
    "ax.set_xticklabels(np.arange(4, len(evals), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCs over time in 3D\n",
    "# ------------------------\n",
    "\n",
    "# select a shorter timewindow\n",
    "cond1 = attention_timeStamps > time_window['Attend'][0]\n",
    "cond2 = attention_timeStamps <= time_window['Attend'][1]\n",
    "idx_time = cond1 & cond2\n",
    "plotdata = data_proj[:,:,idx_time]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.view_init(elev=10., azim=260)\n",
    "ax.plot3D(\n",
    "    plotdata[0, trialdata['attend']==1, :].mean(axis=0),\n",
    "    plotdata[1, trialdata['attend']==1, :].mean(axis=0),\n",
    "    plotdata[2, trialdata['attend']==1, :].mean(axis=0))\n",
    "\n",
    "ax.plot3D(\n",
    "    plotdata[0, trialdata['attend']==2, :].mean(axis=0),\n",
    "    plotdata[1, trialdata['attend']==2, :].mean(axis=0),\n",
    "    plotdata[2, trialdata['attend']==2, :].mean(axis=0))\n",
    "\n",
    "ax.plot3D(\n",
    "    plotdata[0, trialdata['attend']==3, :].mean(axis=0),\n",
    "    plotdata[1, trialdata['attend']==3, :].mean(axis=0),\n",
    "    plotdata[2, trialdata['attend']==3, :].mean(axis=0))\n",
    "\n",
    "ax.set_xlabel('PC 0')\n",
    "ax.set_ylabel('PC 1')\n",
    "ax.set_zlabel('PC 2')\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "ax.axes.zaxis.set_ticklabels([])\n",
    "plt.show()\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "zlim = ax.get_zlim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create animation of PCs over time in 3D.\n",
    "# ----------------------------------------\n",
    "\n",
    "numsamples = 10;\n",
    "\n",
    "# Attaching 3D axis to the figure\n",
    "fig = plt.figure(figsize=(8,8)) \n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# set viewpoint of graph\n",
    "ax.view_init(elev=10., azim=260)\n",
    "\n",
    "# define data to plot\n",
    "attend_RF = data_proj[:, trialdata['attend']==1, :].mean(axis=1)\n",
    "attend_away1 = data_proj[:, trialdata['attend']==2, :].mean(axis=1)\n",
    "attend_away2 = data_proj[:, trialdata['attend']==3, :].mean(axis=1)\n",
    "\n",
    "plotdata = np.array([attend_RF, attend_away1, attend_away2])\n",
    "\n",
    "# Define line and text object\n",
    "lines = animj.def_lines_3D(ax, plotdata)\n",
    "ax.legend(lines, ('Attend RF','Attend Away1','Attend Away2'), loc='lower right', frameon=False)\n",
    "\n",
    "counter = ax.text(20.0, 0.5, 1.0, [],\n",
    "        verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax.transAxes,\n",
    "        color='k', fontsize=15)\n",
    "lines.append(counter)\n",
    "\n",
    "textCounter = 'Time from cue: %1.3f [s]'\n",
    "\n",
    "# set axes\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_zlim(zlim)\n",
    "\n",
    "ax.set_xlabel('PC 0')\n",
    "ax.set_ylabel('PC 1')\n",
    "ax.set_zlabel('PC 2')\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "ax.axes.zaxis.set_ticklabels([])\n",
    "\n",
    "numtimes = np.shape(data_proj)[2]\n",
    "line_anim = animation.FuncAnimation(fig, animj.update_lines_3D_counter, numtimes, \n",
    "                                    fargs=(plotdata, lines, textCounter, attention_timeStamps, numsamples), \n",
    "                                    interval=30, blit=True, repeat=True)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this takes a while!\n",
    "rcParams['animation.html'] = 'html5'\n",
    "line_anim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
